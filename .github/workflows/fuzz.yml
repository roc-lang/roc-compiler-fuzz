on:
  schedule:
    - cron: 22 0/4 * * *
  workflow_dispatch:
    inputs:
      fuzz-time:
        description: Number of seconds to run the fuzzer for
        type: number
        default: 600
      roc-branch:
        description: Roc branch to fuzz
        type: string
        default: main

env:
  roc-branch: ${{ inputs.roc-branch || 'main' }}
  fuzz-time: ${{ inputs.fuzz-time || 1800 }}

# Only allow one copy of this job to run at a time.
# This ensures no merge or cache conflicts.
concurrency:
  group: ${{ github.workflow }}
  cancel-in-progress: false

permissions:
  actions: write
  contents: write
  deployments: write
  id-token: write
  pages: write

jobs:
  fuzz:
    strategy:
      matrix:
        fuzzer: [cli, tokenize]
      fail-fast: false
    env:
      # Updating the version is a trick to help deal with some github cache issues
      # Github cache is not meant to be deleted and overwritten.
      # As such, this flow can sometimes break the cache leading to only save failures.
      # Updating the key generates a new cache but gets around save failures.
      cache-key: ${{ matrix.fuzzer }}-corpus-v2
      fuzzer-exe: fuzz-${{ matrix.fuzzer }}
    runs-on: [ubuntu-24.04]
    steps:
      - name: checkout roc-compiler-fuzz
        uses: actions/checkout@v4
        with:
          path: roc-compiler-fuzz

      - name: checkout roc
        uses: actions/checkout@v4
        with:
          path: roc
          repository: roc-lang/roc
          ref: ${{ env.roc-branch }}

      - name: install zig
        uses: mlugg/setup-zig@v1
        with:
          version: 0.13.0

      - name: install afl++
        run: |
          sudo apt update
          sudo apt install -y afl++
          afl-fuzz --version

      - name: build roc fuzzer (base)
        env:
          AFL_CC_COMPILER: LTO
        run: |
          cd roc
          rm -rf .zig-cache zig-out $ZIG_LOCAL_CACHE_DIR

          zig build -Dfuzz -Dtarget=native-native -Dsystem-afl

          mv zig-out/bin/${{ env.fuzzer-exe }} ../${{ env.fuzzer-exe }}.afl

      # cmplog enables extracting comparision info to get better fuzz results.
      - name: build roc fuzzer (cmplog)
        env:
          AFL_LLVM_CMPLOG: 1
          AFL_CC_COMPILER: LTO
        run: |
          cd roc
          rm -rf .zig-cache zig-out $ZIG_LOCAL_CACHE_DIR

          zig build -Dfuzz -Dtarget=native-native -Dsystem-afl

          mv zig-out/bin/${{ env.fuzzer-exe }} ../${{ env.fuzzer-exe }}.cmplog

      - name: load cached corpus
        id: restore-cache-corpus
        uses: actions/cache/restore@v4
        with:
          key: ${{ env.cache-key }}
          path: corpus
      
      # No matter what we reload examples from the repo.
      # They might get pruned, but we want to make sure we don't miss any new examples.
      - name: copy over initial corpus
        run: |
          mkdir -p corpus/
          cp roc/src/fuzz-corpus/${{ matrix.fuzzer }}/* corpus/

      - name: print corpus
        run: |
          ls corpus

      - name: configure system for fuzzing
        run: |
          sudo afl-system-config
      
      - name: run fuzz jobs
        env:
          AFL_TESTCACHE_SIZE: 500
          AFL_IGNORE_SEED_PROBLEMS: 1
          AFL_IMPORT_FIRST: 1
          AFL_FINAL_SYNC: 1
        run: |
          # This is a rough attempt to follow best practices from: https://aflplus.plus/docs/fuzzing_in_depth/#c-using-multiple-cores
          afl-fuzz \
              -i corpus/ \
              -o fuzz-out/ \
              -V ${{ env.fuzz-time }} \
              -M main \
              -c ./${{ env.fuzzer-exe }}.cmplog \
              -l 2AT \
              -p explore \
              -- ./${{ env.fuzzer-exe }}.afl &
          afl-fuzz \
              -i corpus/ \
              -o fuzz-out/ \
              -V ${{ env.fuzz-time }} \
              -S s1 \
              -p fast \
              -c ./${{ env.fuzzer-exe }}.cmplog \
              -- ./${{ env.fuzzer-exe }}.afl &
          AFL_DISABLE_TRIM=1 afl-fuzz \
              -i corpus/ \
              -o fuzz-out/ \
              -V ${{ env.fuzz-time }} \
              -S s2 \
              -p explore \
              -- ./${{ env.fuzzer-exe }}.afl &
          afl-fuzz \
              -i corpus/ \
              -o fuzz-out/ \
              -V ${{ env.fuzz-time }} \
              -S s3 \
              -p exploit \
              -- ./${{ env.fuzzer-exe }}.afl &
          wait
      
      - name: fuzz stats
        run: |
          afl-whatsup -d fuzz-out/

      - name: minimize corpus
        env:
          # TODO: why is this needed?
          # Can we remove it?
          # afl-cmin seems to work correctly with this.
          AFL_SKIP_BIN_CHECK: 1
        run: |
          afl-cmin \
              -i fuzz-out/main/queue/ \
              -o fuzz-cmin/ \
              -T all \
              -- ./${{ env.fuzzer-exe }}.afl

          # TODO: tmin is too slow, do we need to minimize at all?
          # mkdir fuzz-tmin
          # cd fuzz-cmin
          # ls | parallel \
          #   afl-tmin \
          #       -i {} \
          #       -o ../fuzz-tmin/{} \
          #       -- ../${{ env.fuzzer-exe }}.afl
          # cd ..

          rm -rf corpus
          # mv fuzz-tmin corpus
          mv fuzz-cmin corpus

      - name: print corpus
        run: |
          ls corpus

      # delete previous cache to enable overwritting it.
      - name: delete previous cache
        if: ${{ steps.restore-cache-corpus.outputs.cache-hit }}
        continue-on-error: true
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          cd roc-compiler-fuzz
          gh extension install actions/gh-actions-cache
          gh actions-cache delete "${{ env.cache-key }}" --confirm

      - name: save corpus
        id: save-cache-corpus
        uses: actions/cache/save@v4
        with:
          key: ${{ env.cache-key }}
          path: corpus

      - name: minimize crashes
        run: |
          mv fuzz-out/main/crashes/ fuzz-crashes
          mkdir fuzz-out/main/crashes/

          cd fuzz-crashes
          # TODO: most of these are probably duplicate failures and a waste to minimize
          # Maybe limit to a random subset or the already shortest files.
          # That will help if this stage gets too slow.
          ls | parallel \
            afl-tmin \
                -i {} \
                -o ../fuzz-out/main/crashes/{} \
                -- ../${{ env.fuzzer-exe }}.afl

      - name: list failures
        run: |
          echo "Crashes:"
          ls fuzz-out/main/crashes/
          echo -e "\nHangs:"
          ls fuzz-out/main/hangs/

      # calculate list of crashes/hangs to report
      # TODO: maybe move database to its own branch to reduce churn.
      - name: record results
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          cd roc-compiler-fuzz
          git config --global user.name "${{ github.actor }}"
          git config --global user.email "${{ github.actor }}@users.noreply.github.com"

          # allow for 10 tries to update the database.
          for i in {1..10}; do
            git fetch origin main
            git reset --hard origin/main
            zig build update-database -- ../roc ${{ matrix.fuzzer }} ../fuzz-out
            git add data.json
            git commit -m "update fuzzing database (${{ matrix.fuzzer }})"
            if git push; then
              break
            fi
            sleep 10
          done

  deploy:
    # deploy site even if one of the fuzzers fails.
    if: always()
    needs: [fuzz]
    runs-on: ubuntu-24.04
    steps:
      - name: checkout roc-compiler-fuzz
        uses: actions/checkout@v4

      - name: install zig
        uses: mlugg/setup-zig@v1
        with:
          version: 0.13.0

      - name: generate site
        run: |
          zig build generate-website

      - name: upload website artifacts
        uses: actions/upload-pages-artifact@v3
        with:
          path: 'www'
      - name: deploy site
        uses: actions/deploy-pages@v4
